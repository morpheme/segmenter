Preliminaries:
- DONE:  Modify segmenterBasic for batch mode
- IN PROGRESS: Rejigger collection code to grab hashtags as described below
	- Problem: It is possible to avoid authentication and use the REST API exclusively to generate 
	hashtags; however, that option means rate limiting and limited returns. (If selecting
	by USA WOEID to somewhat guarantee English tweets the hits are low in quantity; if not 
	filtering by location, the hits are low in quality.) Also, there is no reason that the
	dataset should be limited to trending hashtags.
	- Solution: Continue with using Streaming API. Just filter by hashtag text in Entities and 
	user language. The quantity issue will be 99% solved and the quality issue 90% solved.
	- Add hook into database in addition to the file output format currently used.
		- pyhashseg now takes three options: string, flag, or None. The first two are already
		handled; the final option will be the default method and will retrieve database members
		
	- Libraries issues: 
		- Where is tweetstream installed? 
		- Does it have the OAuth info hand-coded?
		- If so, are twitter__login.py and its relatives just a waste of time?
- Modify segmenterBasic to segmenterExtended
	- Establish baseline for probs of previously unseen words.  
		- Does this mean somehow weighting news results more heavily?  
		- How does this interface with default backoff prob?
	- Add code for Bing API
		

Data collection:
- Q: SHOULD I INCLUDE NON-HASHTAG CONCATENATED STRINGS AS A CONTROL, OR WILL THE BASIC VERSION SUFFICE?
- 100 unique instances of hashtags:
	- m from general trends
	- n from personal feed
	- No particular motivation for this breakdown, other than that my personal feed follows 
	several news sources that propagate hashtags that reach the general population rather 
	than a particular demographic. Talk to Rob about wisdom of this.
	- Note time collected over!

Data processing:
- Segment all strings with all algos in one pass


Evaluation:
- Determine number of judges available. Hopefully more than one.
- Send segmented string to judge. She must decide if it is a legitimate English string and issues a 
binary score.
- Each concatenated string is presented twice: a segmented version from each algo. The judge does not
know how the segmented string was produced wrt to algos.











*****************
*   Old stuff   *
*****************
Gold evaluation:
- Determine number of judges available. Hopefully more than one.
- Manual evaluation: pick the best candidate with format:
	Input: choosespain		
	Possible output: choose spain (entered by judge)
	
	Input: #eastwooding	
	Possible output: eastwooding (entered by judge)
	
	...etc.

	- Note that this format allows for long input and output strings, such as Norvig's H2G2 example. 
	This format will be followed in all evaluations.
	- TO DO: 
		- Write script that pulls hashtags from database to interact with judges. Hopefully it can
		present an editable string so as to cut down on errors.
	
- General points:
	- Suppose that I gave the judge(s) the predetermined max mcandidate derived from the segmenter script.
	They would then simply be assessing whether that mcandidate was correct. However, that introduces a
	bias towards the performance of the segmenter: there is no chance to evaluate the "best" segmentation,
	as determined by the judge(s). 
	- However, the evaluation method as described isn't without its issues: it may be the case that judges 
	disagree on segmentation and produce up to n candidates for n judges. The variability of n makes it
	difficult to use in Cohen's or Fleiss' kappa (see k in http://en.wikipedia.org/wiki/Fleiss%27_kappa#Worked_example).
	- So the basic idea, if the gold standard doesn't include manually edited strings:
		-let the basic version of the segmenter do its thing. Then give each judge the original and the basic 
		segmented version of it, and (s)he is allowed to place the latter in one of two categories: wrong or 
		(possibly) right. (By possibly, I refer to the case that there may be more than one acceptable 
		segmentation for a string. The judge must simply assess whether the segmented string is a well-formed 
		phrase.)
		- Concurrently and randomly, also offer each judge the original and the extended segmented version, 
		with the same categorization taking place. Consequently the complete evaluation offers two opportunities
		to judge the concatenated string.
		- In no case is the judge informed as to which segmented version is being offered. 


First iteration:
- Run segmenterBasic: take in the data file and output a modified version with format:
	Input: choosespain		
	Output: choose spain
	
	Input: #eastwooding	
	Output: eastwood ing	#decent! I would have expected "east wood in g".
	
	...etc.
	
Second iteration:
- Run segmenterExtended: take in the data file and output a modified version with format:
	Input: choosespain		
	Possible output: choose spain
	
	Input: #eastwooding	
	Possible output: eastwooding	
	
	...etc.

Evaluation:
-

If necessary:
- Repeat above with tweaks to segmenterExtended algorithm until y% > x%


